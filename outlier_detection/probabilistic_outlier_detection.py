# Probabilistic outlier detection using Gaussian Mixture Model

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA

def probabilistic_outlier_detection(data, X_pca_2d=None, n_components=3, threshold_percentile=5):
  # Prepare data
  X_encoded = data.drop(['NObeyesdad'], axis=1)
  y_original = data['NObeyesdad']
  
  # Probabilistic Outlier Detection
  print("\n==== Probabilistic Outlier Detection (Gaussian Mixture Model) ====")
  print(f"Using {n_components} Gaussian components")

  # Fit Gaussian Mixture Model using EM algorithm
  gmm = GaussianMixture(
    n_components=n_components,
    covariance_type='full',
    random_state=42,
    max_iter=100
  )
  gmm.fit(X_encoded)

  # Calculate log-likelihood for each sample
  # Lower log-likelihood = less likely to be generated by model = outlier
  log_likelihood = gmm.score_samples(X_encoded)
  
  # Set threshold at bottom threshold_percentile% (default 5%)
  threshold = np.percentile(log_likelihood, threshold_percentile)
  outlier = log_likelihood < threshold
  
  print(f"\nOutlier Detection Results:")
  print(f"  • Threshold ({threshold_percentile}th percentile log-likelihood): {threshold:.4f}")
  print(f"  • Outliers detected: {outlier.sum()} ({outlier.sum()/len(outlier)*100:.2f}%)")
  print(f"  • Normal samples: {(~outlier).sum()}")
  print(f"  • EM algorithm converged: {gmm.converged_}")

  # Visualize outliers
  print("\nVisualizing outliers")    
  # Plot: Outliers on PCA scatter plot
  plt.figure(figsize=(8, 6))
  plt.scatter(X_pca_2d[~outlier, 0], X_pca_2d[~outlier, 1], color='blue', alpha=0.5, label='Normal', s=20)
  plt.scatter(X_pca_2d[outlier, 0], X_pca_2d[outlier, 1], color='red', alpha=0.8, label='Outlier', s=50, marker='x', linewidths=2)
  plt.xlabel('PC1')
  plt.ylabel('PC2')
  plt.title('Probabilistic Outlier Detection - PCA Visualization')
  plt.legend()
  plt.grid(alpha=0.3)
  plt.tight_layout()
  plt.show()

  print("\nOutlier Distribution by Obesity Class:")
  for class_name in np.unique(y_original):
    class_mask = y_original == class_name
    class_outliers = outlier[class_mask].sum()
    class_total = class_mask.sum()
    print(f"  • {class_name}: {class_outliers}/{class_total} ({class_outliers/class_total*100:.2f}%)")
  
  print("\nOutlier Analysis:")
  print("Probabilistic outliers represent samples with low probability under the learned Gaussian mixture.")
  print("These are data points that deviate significantly from the typical patterns in the obesity dataset.")
  print("\nDecision: Keep outliers for analysis as they represent valid edge cases and rare obesity patterns")
  print("that could be important for understanding the full spectrum of obesity-related features.\n")

  return {
    'n_outliers': int(outlier.sum()),
    'percentage': outlier.sum() / len(outlier) * 100,
    'threshold': float(threshold),
    'n_components': n_components,
    'gmm_converged': bool(gmm.converged_)
  }